{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "\n",
    "from scipy.integrate import quad\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from SyntheticDataModule import *\n",
    "from estimators import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rct_size = 500\n",
    "m = 2\n",
    "CD = 8\n",
    "UC = 0\n",
    "\n",
    "jD = read_json('complete-IC/diffPO.json', CD, UC, [\"IPCW\", \"CDR\"])\n",
    "test_signals = jD[\"test_signals\"]\n",
    "\n",
    "RCTData = SyntheticDataModule(jD['save_df'], CD, rct_size, 0, jD['RCT']['px_dist'], jD['RCT']['px_args'], jD['RCT']['prop_fn'], jD['RCT']['prop_args'], jD['RCT']['tte_params'])\n",
    "OSData = SyntheticDataModule(jD['save_df'], CD, rct_size * m, 1, jD['OS']['px_dist'], jD['OS']['px_args'], jD['OS']['prop_fn'], jD['OS']['prop_args'], jD['OS']['tte_params'])\n",
    "\n",
    "df_rct_oracle, df_rct = RCTData.get_df()\n",
    "df_os_oracle, df_os = OSData.get_df()\n",
    "\n",
    "df_combined = pd.concat([df_rct, df_os], axis=0, ignore_index=True)  # merge the dataframes into one\n",
    "df_comb_drop = df_combined.query('Delta == 1').reset_index(drop=True).copy()  # drop the censored observations\n",
    "\n",
    "# Estimate the nuisance parameters for the combined dataframe\n",
    "\n",
    "df_combined['P(S=1|X)'] = prop_score_est(df_combined.copy(), 'S', jD['cov_list'], 'logistic')\n",
    "\n",
    "df_combined.loc[df_combined.S==0, 'P(A=1|X,S)'] = prop_score_est(df_combined.query('S==0').copy(), 'A', jD['cov_list'], 'logistic')\n",
    "df_combined.loc[df_combined.S==1, 'P(A=1|X,S)'] = prop_score_est(df_combined.query('S==1').copy(), 'A', jD['cov_list'], 'logistic')\n",
    "\n",
    "Gb_C, Fb_Y = est_surv(df_combined, jD['cov_list'], tte_model='coxph')\n",
    "fill_barG(df_combined, jD['cov_list'], Gb_C)\n",
    "\n",
    "if any(\"IPCW\" in key for key in test_signals.keys()):\n",
    "    ipcw_est(df_combined, S=0)\n",
    "    ipcw_est(df_combined, S=1)\n",
    "\n",
    "if any(\"IPW-Impute\" in key for key in test_signals.keys()):\n",
    "    ipw_est(df_combined, S=0, baseline='impute')  # censored observations are IMPUTED\n",
    "    ipw_est(df_combined, S=1, baseline='impute')  # censored observations are IMPUTED\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "if any(\"CDR\" in key for key in test_signals.keys()):\n",
    "    cdr_est(df_combined, jD['cov_list'], Gb_C, Fb_Y, S=0)  \n",
    "    cdr_est(df_combined, jD['cov_list'], Gb_C, Fb_Y, S=1) \n",
    "    \n",
    "t2 = time()\n",
    "print(f\"Time:{t2 - t1}\")\n",
    "\n",
    "# Estimate the nuisance parameters for the combined dataframe with censored observations dropped\n",
    "    \n",
    "if any(\"IPW-Drop\" in key for key in test_signals.keys()):\n",
    "    df_comb_drop['P(S=1|X)'] = prop_score_est(df_comb_drop.copy(), 'S', jD['cov_list'], 'logistic')\n",
    "\n",
    "    df_comb_drop.loc[df_comb_drop.S==0, 'P(A=1|X,S)'] = prop_score_est(df_comb_drop.query('S==0').copy(), 'A', jD['cov_list'], 'logistic')\n",
    "    df_comb_drop.loc[df_comb_drop.S==1, 'P(A=1|X,S)'] = prop_score_est(df_comb_drop.query('S==1').copy(), 'A', jD['cov_list'], 'logistic')\n",
    "\n",
    "    ipw_est(df_comb_drop, S=0, baseline='drop')  # censored observations are DROPPED\n",
    "    ipw_est(df_comb_drop, S=1, baseline='drop')  # censored observations are DROPPED\n",
    "\n",
    "summary_df = pd.concat([RCTData.summary(plot=True), OSData.summary(plot=True)], axis=0, ignore_index=True)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_combined\n",
    "df_new_drop = df_comb_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CDR-S0-ATE: {:.2f}\\n'.format(df_new['S0_cdr_est_CATE'].mean()))\n",
    "print('CDR-S1-ATE: {:.2f}\\n'.format(df_new['S1_cdr_est_CATE'].mean()))\n",
    "\n",
    "print('IPCW-S0-Y0: {:.2f}'.format(df_new['S0_ipcw_est_Y0'].mean()))\n",
    "print('IPCW-S0-Y1: {:.2f}'.format(df_new['S0_ipcw_est_Y1'].mean()))\n",
    "print('IPCW-S0-ATE: {:.2f}\\n'.format(df_new['S0_ipcw_est_CATE'].mean()))\n",
    "\n",
    "print('IPCW-S1-Y0: {:.2f}'.format(df_new['S1_ipcw_est_Y0'].mean()))\n",
    "print('IPCW-S1-Y1: {:.2f}'.format(df_new['S1_ipcw_est_Y1'].mean()))\n",
    "print('IPCW-S1-ATE: {:.2f}\\n'.format(df_new['S1_ipcw_est_CATE'].mean()))\n",
    "\n",
    "# print('IPW-Impute-S0-Y0: {:.2f}'.format(df_new['S0_impute_ipw_est_Y0'].mean()))\n",
    "# print('IPW-Impute-S0-Y1: {:.2f}'.format(df_new['S0_impute_ipw_est_Y1'].mean()))\n",
    "# print('IPW-Impute-S0-ATE: {:.2f}\\n'.format(df_new['S0_impute_ipw_est_CATE'].mean()))\n",
    "\n",
    "# print('IPW-Impute-S1-Y0: {:.2f}'.format(df_new['S1_impute_ipw_est_Y0'].mean()))\n",
    "# print('IPW-Impute-S1-Y1: {:.2f}'.format(df_new['S1_impute_ipw_est_Y1'].mean()))\n",
    "# print('IPW-Impute-S1-ATE: {:.2f}\\n'.format(df_new['S1_impute_ipw_est_CATE'].mean()))\n",
    "\n",
    "# print('IPW-Drop-S0-Y0: {:.2f}'.format(df_new_drop['S0_drop_ipw_est_Y0'].mean()))\n",
    "# print('IPW-Drop-S0-Y1: {:.2f}'.format(df_new_drop['S0_drop_ipw_est_Y1'].mean()))\n",
    "# print('IPW-Drop-S0-ATE: {:.2f}\\n'.format(df_new_drop['S0_drop_ipw_est_CATE'].mean()))\n",
    "\n",
    "# print('IPW-Drop-S1-Y0: {:.2f}'.format(df_new_drop['S1_drop_ipw_est_Y0'].mean()))\n",
    "# print('IPW-Drop-S1-Y1: {:.2f}'.format(df_new_drop['S1_drop_ipw_est_Y1'].mean()))\n",
    "# print('IPW-Drop-S1-ATE: {:.2f}'.format(df_new_drop['S1_drop_ipw_est_CATE'].mean()))\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 1743\n",
    "\n",
    "s = df_combined.loc[row, 'S']\n",
    "a = df_combined.loc[row, 'A']\n",
    "x = np.array(df_combined.loc[row, jD['cov_list']])\n",
    "T = df_combined.loc[row, 'T']\n",
    "Delta = df_combined.loc[row, 'Delta']\n",
    "\n",
    "df_combined.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_surv_(Gb_C[f't_S{s}_A{a}'], Gb_C[f'St_S{s}_A{a}'], T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_int_term_(s, a, x, T, Gb_C, Fb_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Ystar_(s, a, x, Delta, T, Gb_C, Fb_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_Qfunc_(s, a, x, T, Fb_Y, thresh=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Gb(T|X,S,A)'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[['S1_cdr_est_CATE', 'S1_ipcw_est_CATE']].sort_values(by='S1_cdr_est_CATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[['S1_cdr_est_CATE', 'S1_ipcw_est_CATE']].sort_values(by='S1_cdr_est_CATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_thr = 0.05\n",
    "\n",
    "df_new = df_combined[(p_thr < df_combined['P(S=1|X)']) & (df_combined['P(S=1|X)'] < 1 - p_thr) &\\\n",
    "            (p_thr < df_combined['P(A=1|X,S)']) & (df_combined['P(A=1|X,S)'] < 1 - p_thr) &\\\n",
    "            (p_thr < df_combined['Gb(T|X,S,A)'])].copy().reset_index(drop=True)\n",
    "\n",
    "# df_new_drop = df_comb_drop[(p_thr < df_comb_drop['P(S=1|X)']) & (df_comb_drop['P(S=1|X)'] < 1 - p_thr) &\\\n",
    "#             (p_thr < df_comb_drop['P(A=1|X,S)']) & (df_comb_drop['P(A=1|X,S)'] < 1 - p_thr)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.sort_values(by='P(S=1|X)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a = 1, 1\n",
    "ty, sty = Fb_Y[f't_S{s}_A{a}'], Fb_Y[f'St_S{s}_A{a}']\n",
    "tc, stc = Gb_C[f't_S{s}_A{a}'], Gb_C[f'St_S{s}_A{a}']\n",
    "\n",
    "t_arr = tc #\n",
    "st_arr = stc  \n",
    "\n",
    "t1 = time()\n",
    "func = interp1d(t_arr, st_arr, kind='nearest', fill_value='extrapolate')\n",
    "result, error = quad(func, 0, t_arr.max() + 10, limit=5)\n",
    "\n",
    "print(f\"Time: {time()-t1:.2f} s.\")\n",
    "print(f\"Result of integration: {result}, error: {error}\")\n",
    "\n",
    "xnew = np.arange(0, t_arr.max() + 10, 0.1)\n",
    "ynew = func(xnew)   # use interpolation function returned by `interp1d`\n",
    "plt.plot(t_arr, st_arr, 'o', xnew, ynew, '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a = 1, 1\n",
    "x = np.zeros(CD + 1)\n",
    "ty, sty = Fb_Y[f't_S{s}_A{a}'], Fb_Y[f'St_S{s}_A{a}']\n",
    "tc, stc = Gb_C[f't_S{s}_A{a}'], Gb_C[f'St_S{s}_A{a}']\n",
    "\n",
    "t_arr = ty #\n",
    "st_arr = sty  \n",
    "\n",
    "t1 = time()\n",
    "func = interp1d(t_arr, st_arr, kind='nearest', fill_value='extrapolate')\n",
    "result, error = quad(func, 0, t_arr.max(), limit=5)\n",
    "\n",
    "print(f\"Time: {time()-t1:.2f} s.\")\n",
    "print(f\"Result of integration: {result}, error: {error}\")\n",
    "\n",
    "xnew = np.arange(0, t_arr.max(), 0.1)\n",
    "ynew = func(xnew)   # use interpolation function returned by `interp1d`\n",
    "plt.plot(t_arr, st_arr, 'o', xnew, ynew, '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trange = np.linspace(0,10,51)\n",
    "q_arr_normal = [eval_Qfunc_(s, a, x, T, Fb_Y) for T in Trange]\n",
    "q_arr_batch = eval_Qfunc_arr_(s, a, x, Trange, Fb_Y)\n",
    "plt.figure()\n",
    "plt.plot(Trange, q_arr_normal, label='q_normal')\n",
    "plt.plot(Trange, q_arr_batch, label='q_batch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_space = np.linspace(-10,10,401)\n",
    "cov_name = 'X1'\n",
    "os_oracle_prop = OSData.calc_oracle_prop(x_space, cov_name)\n",
    "plt.figure()\n",
    "plt.plot(x_space, os_oracle_prop)\n",
    "plt.xlabel(cov_name)\n",
    "plt.ylabel(f'P(A=1|{cov_name},S=1)')\n",
    "plt.title(f'Oracle propensity score in study S=1 wrt covariate {cov_name}')\n",
    "plt.show()\n",
    "\n",
    "t = np.linspace(0,20,101)\n",
    "cov_vals = [0, 0, 0, 0]\n",
    "tbs_Y0 = RCTData.get_oracle_surv_curve(t, cov_vals, 'Y0')\n",
    "tbs_Y1 = RCTData.get_oracle_surv_curve(t, cov_vals, 'Y1')\n",
    "tbs_C0 = RCTData.get_oracle_surv_curve(t, cov_vals, 'C0')\n",
    "tbs_C1 = RCTData.get_oracle_surv_curve(t, cov_vals, 'C1')\n",
    "plt.figure()\n",
    "plt.plot(t, tbs_Y0, label='Y0', alpha= 0.4, ls ='--')\n",
    "plt.plot(t, tbs_Y1, label='Y1', alpha= 1, ls ='-.')\n",
    "plt.plot(t, tbs_C0, label='C0', alpha= 0.4)\n",
    "plt.plot(t, tbs_C1, label='C1', alpha= 0.4)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(r'$S(t)$')\n",
    "plt.title(f'True survival curves in study S=0 with X={cov_vals}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
